apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: shk-app
spec:
  type: Python
  sparkVersion: 3.0.1
  pythonVersion: '3'
  sparkConf:
    "spark.metrics.conf.*.source.jvm.class": "org.apache.spark.metrics.source.JvmSource"
    "spark.metrics.appStatusSource.enabled": "true"
  hadoopConf:
    "fs.s3a.endpoint": "s3"
    "fs.s3a.access.key": ""
  mainApplicationFile: 's3a:///spark-demo-a4d00352-25f3-44cc-bb61-0b07cd7b33a1/wordcount.py'
  image: "quay.io/guimou/pyspark-odh:s3.0.1-h3.3.0_v0.0.3"
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
  timeToLiveSeconds: 15
  driver:
    serviceAccount: 'spark-operator-spark'
    labels:
      type: spark-application
    env:
      - name: S3_ENDPOINT_URL
        valueFrom:
          configMapKeyRef:
            name: spark-demo
            key: BUCKET_HOST
      - name: BUCKET_NAME
        valueFrom:
          configMapKeyRef:
            name: spark-demo
            key: BUCKET_NAME
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: spark-demo
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: spark-demo
            key: AWS_SECRET_ACCESS_KEY
    cores: 1
    coreLimit: "1"
  executor:
    labels:
      type: spark-application
    instances: 2
    cores: 1
    coreLimit: "1"
  monitoring:
    exposeDriverMetrics: true
    exposeExecutorMetrics: true
    prometheus:
      jmxExporterJar: "/prometheus/jmx_prometheus_javaagent-0.15.0.jar"
      portName: 'tcp-prometheus'
  