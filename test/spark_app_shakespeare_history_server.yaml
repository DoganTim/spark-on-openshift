apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: shk-app
spec:
  type: Python
  sparkVersion: 3.0.1
  pythonVersion: '3'
  sparkConf:
    "spark.metrics.conf.*.source.jvm.class": "org.apache.spark.metrics.source.JvmSource"
    "spark.metrics.appStatusSource.enabled": "true"
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "s3a://spark-history-server-17bb3752-c068-49cb-8f73-44d3adcd7095/logs-dir/"
    "spark.hadoop.fs.s3a.bucket.spark-history-server-17bb3752-c068-49cb-8f73-44d3adcd7095.endpoint": "s3.openshift-storage.svc"
    "spark.hadoop.fs.s3a.bucket.spark-history-server-17bb3752-c068-49cb-8f73-44d3adcd7095.access.key": "cMPiQBiLvaUpJx7W461E"
    "spark.hadoop.fs.s3a.bucket.spark-history-server-17bb3752-c068-49cb-8f73-44d3adcd7095.secret.key": "bC7k9NxX7vZoMCUhFMgN7+D+Z97clr/VzC87xNjP"
    "spark.hadoop.fs.s3a.bucket.spark-history-server-17bb3752-c068-49cb-8f73-44d3adcd7095.path.style.access": "true"
    "spark.hadoop.fs.s3a.bucket.spark-history-server-17bb3752-c068-49cb-8f73-44d3adcd7095.connection.ssl.enabled": "false"
  mainApplicationFile: 'local:///home/wordcount.py'
  image: "quay.io/guimou/pyspark-odh:s3.0.1-h3.3.0_v0.0.3"
  volumes:
    - name: wordcount
      configMap:
        name: wordcount
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
  timeToLiveSeconds: 15
  driver:
    serviceAccount: 'spark-operator-spark'
    labels:
      type: spark-application
    env:
      - name: S3_ENDPOINT_URL
        valueFrom:
          configMapKeyRef:
            name: spark-demo
            key: BUCKET_HOST
      - name: BUCKET_NAME
        valueFrom:
          configMapKeyRef:
            name: spark-demo
            key: BUCKET_NAME
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: spark-demo
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: spark-demo
            key: AWS_SECRET_ACCESS_KEY
    cores: 1
    coreLimit: "1"
    volumeMounts:
      - name: wordcount
        mountPath: '/home/'
  executor:
    labels:
      type: spark-application
    instances: 2
    cores: 1
    coreLimit: "1"
  monitoring:
    exposeDriverMetrics: true
    exposeExecutorMetrics: true
    prometheus:
      jmxExporterJar: "/prometheus/jmx_prometheus_javaagent-0.15.0.jar"
      portName: 'tcp-prometheus'
  